{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import mrcfile\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch import FloatTensor as FT\n",
    "from torch.autograd import Variable as V\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "rawData = \"/home/tyche/paddle_SN2N/raw_data/\"\n",
    "Datasets = \"/home/tyche/paddle_SN2N/datasets/\"\n",
    "\n",
    "\n",
    "def get_all_files(directory):\n",
    "    file_list = list()\n",
    "    n_files = 0\n",
    "    for file in os.listdir(directory):\n",
    "        file_list.append(f\"{directory}/{file}\")\n",
    "        n_files += 1\n",
    "    return file_list, n_files\n",
    "\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_index(arr):\n",
    "    groups = {}\n",
    "    for row in arr:\n",
    "        key = row[0]\n",
    "        if key not in groups:\n",
    "            groups[key] = []\n",
    "        groups[key].append(row)\n",
    "    \n",
    "    # 转换为NumPy数组\n",
    "    for key in groups:\n",
    "        groups[key] = np.array(groups[key])\n",
    "    \n",
    "    return groups\n",
    "arr = np.array([\n",
    "    [1, 2, 3],\n",
    "    [1, 4, 5],\n",
    "    [2, 6, 7],\n",
    "    [2, 8, 9],\n",
    "    [3, 10, 11]\n",
    "])\n",
    "\n",
    "# 示例\n",
    "groups_dict = split_by_index(arr)\n",
    "for key, group in groups_dict.items():\n",
    "    print(f\"index {key}:\")\n",
    "    print(group)\n",
    "    print()\n",
    "\n",
    "def get_map_from_predictions():\n",
    "    # chunk_files = [os.path.join('./predictions', f) for f in os.listdir('./predictions') if f.endswith('.npz')]\n",
    "    chunk_files = [os.path.join('./datasets', f) for f in os.listdir('./datasets') if f.endswith('.npz')]\n",
    "    chunk_positions = [os.path.splitext(os.path.basename(f))[0].split(\"_\") for f in chunk_files]\n",
    "    chunk_positions = np.array(chunk_positions, dtype=int)\n",
    "    groups = split_by_index(chunk_positions)\n",
    "\n",
    "    \n",
    "    # for chunk_file, chunk_position in zip(chunk_files, chunk_positions):\n",
    "     \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.tensor([[[[0, 1], [1, 1]], [[1, 1], [1, 1]]],\n",
    "                       [[[1, 0], [1, 1]], [[1, 1], [1, 1]]],\n",
    "                       [[[1, 1], [0, 1]], [[1, 1], [1, 1]]],\n",
    "                       [[[1, 1], [1, 0]], [[1, 1], [1, 1]]],\n",
    "                       [[[1, 1], [1, 1]], [[0, 1], [1, 1]]],\n",
    "                       [[[1, 1], [1, 1]], [[1, 0], [1, 1]]],\n",
    "                       [[[1, 1], [1, 1]], [[1, 1], [0, 1]]],\n",
    "                       [[[1, 1], [1, 1]], [[1, 1], [1, 0]]],])\n",
    "kernel = torch.tensor([[[[1, 0], [0, 1]], [[0, 1], [1, 0]]],  \n",
    "                       [[[0, 1], [1, 0]], [[1, 0], [0, 1]]]]).float()\n",
    "kernel = torch.tensor([[[[1, 0], [0, 1]], [[0, 1], [1, 0]]], \n",
    "                       [[[0, 1], [1, 0]], [[1, 0], [0, 1]]]])\n",
    "\n",
    "kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.choice([0, 1], size=(5, 5, 5))\n",
    "colors = ['yellow', 'blue', 'green', 'red', 'purple']\n",
    "cmap = ListedColormap(colors)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10), subplot_kw={'projection': '3d'})\n",
    "axes = axes.flatten()\n",
    "for i in range(min(8, kernel.shape[0])):  # 最多显示6个子图\n",
    "    ax = axes[i]\n",
    "    ax.voxels(kernel[i], facecolors=cmap(i%len(colors)), edgecolor='k', alpha=0.8)\n",
    "    ax.set_title(f'kernel {i+1}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.tensor([[[1, 0], [0, 1]],\n",
    "                      [[0, 1], [1, 0]]]).float() / 2\n",
    "colors = ['yellow', 'blue', 'green', 'red', 'purple']\n",
    "cmap = ListedColormap(colors[::-1])\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 可视化每个卷积核\n",
    "for i in range(kernel.shape[0]):\n",
    "    ax = axes[i]\n",
    "    # 使用matshow可视化2D卷积核\n",
    "    im = ax.matshow(kernel[i], cmap=cmap)\n",
    "    ax.set_title(f'Kernel {i+1}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(8).view(2, 2, 2)\n",
    "dims = [[0, 1], [1, 2], [0, 2]]\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 10), subplot_kw={'projection': '3d'})\n",
    "axes = axes.flatten()\n",
    "for i in range(3):  \n",
    "    ax = axes[i]\n",
    "    ax.voxels(torch.rot90(x, 1, dims[i]), facecolors=cmap(i%len(colors)), edgecolor='k', alpha=0.8)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "axes[3].voxels(x)\n",
    "plt.show()\n",
    "torch.rot90(x, 1, [0, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "def combine_tensors_to_gif(\n",
    "    tensors,\n",
    "    titles,\n",
    "    output_path: str = \"combined_tensors.gif\",\n",
    "    fps: int = 2,\n",
    "    cmap: str = \"viridis\",\n",
    "    figsize: tuple = (12, 8),\n",
    "    dpi: int = 100,\n",
    "    show_colorbar: bool = True,\n",
    "    vmin = 0,\n",
    "    vmax = 255\n",
    "):\n",
    "\n",
    "    # Check all tensors have the same depth\n",
    "    depths = [tensor.shape[0] for tensor in tensors]\n",
    "    depth = max(depths)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate frames for GIF\n",
    "    frames = []\n",
    "    \n",
    "    for i in range(depth):\n",
    "        # Create figure and axes\n",
    "        fig, axes = plt.subplots(1, len(tensors), figsize=figsize, dpi=dpi, sharey=True)\n",
    "        if len(tensors) == 1:\n",
    "            axes = [axes]  # Ensure axes is always a list\n",
    "        \n",
    "        # Plot each tensor's current layer\n",
    "        ims = []\n",
    "        for j, tensor in enumerate(tensors):\n",
    "            im = axes[j].imshow(tensor[i, :, :], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "            ims.append(im)\n",
    "            axes[j].set_title(f\"{titles[j]}_Layer_{i}\")\n",
    "        \n",
    "        # Add colorbar if specified\n",
    "        if show_colorbar:\n",
    "            fig.subplots_adjust(right=0.9)\n",
    "            cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "            fig.colorbar(ims[0], cax=cbar_ax)\n",
    "        \n",
    "        # Render figure to numpy array\n",
    "        plt.tight_layout()\n",
    "        fig.canvas.draw()\n",
    "        frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "        frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        frames.append(frame)\n",
    "        \n",
    "        # Close figure to free memory\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Save frames as GIF\n",
    "    imageio.mimsave(output_path, frames, fps=fps, loop=0)\n",
    "    print(f\"GIF saved to: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample 3D tensors\n",
    "    tensor1 = np.random.rand(10, 50, 50)  # 10 layers, 50x50 each\n",
    "    tensor2 = np.random.rand(10, 50, 50)  # 10 layers, 50x50 each\n",
    "    \n",
    "    # Add structure to tensors for better visualization\n",
    "    for i in range(10):\n",
    "        x, y = np.ogrid[-i:50-i, -i:50-i]\n",
    "        mask = x*x + y*y <= (25-i)**2\n",
    "        tensor1[i][mask] = 2 * tensor1[i][mask]\n",
    "        tensor2[i][mask] = 3 * tensor2[i][mask]\n",
    "    \n",
    "    # Create a sphere tensor\n",
    "    sphere = np.zeros((10, 50, 50))\n",
    "    for z in range(10):\n",
    "        for y in range(50):\n",
    "            for x in range(50):\n",
    "                if (x-25)**2 + (y-25)**2 + (z-4)**2 <= 40:\n",
    "                    sphere[z, y, x] = 1.0\n",
    "    \n",
    "    # Save all tensors to a single GIF\n",
    "    combine_tensors_to_gif(\n",
    "        tensors=[tensor1,\n",
    "            tensor2,\n",
    "            sphere],\n",
    "        titles=['t1', 't2', 't3'],\n",
    "        output_path=\"combined_tensors.gif\",\n",
    "        fps=24,\n",
    "        cmap=\"viridis\"\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from typing import Dict, Optional\n",
    "import os\n",
    "\n",
    "def combine_tensors_to_gif(\n",
    "    tensors: Dict[str, np.ndarray],\n",
    "    output_path: str = \"combined_tensors.gif\",\n",
    "    fps: int = 2,\n",
    "    cmap: str = \"viridis\",\n",
    "    figsize: tuple = (12, 8),\n",
    "    dpi: int = 100,\n",
    "    show_colorbar: bool = True,\n",
    "    vmin: Optional[float] = None,\n",
    "    vmax: Optional[float] = None\n",
    ") -> None:\n",
    "\n",
    "    # Check all tensors have the same depth\n",
    "    depths = [tensor.shape[0] for tensor in tensors.values()]   \n",
    "    depth = max(depths)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate frames for GIF\n",
    "    frames = []\n",
    "    \n",
    "    for i in range(depth):\n",
    "        # Create figure and axes\n",
    "        fig, axes = plt.subplots(1, len(tensors), figsize=figsize, dpi=dpi, sharey=True)\n",
    "        if len(tensors) == 1:\n",
    "            axes = [axes]  # Ensure axes is always a list\n",
    "        \n",
    "        # Plot each tensor's current layer\n",
    "        ims = []\n",
    "        for j, (name, tensor) in enumerate(tensors.items()):\n",
    "            im = axes[j].imshow(tensor[i % tensor.shape[0]], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "            ims.append(im)\n",
    "            axes[j].set_title(f\"{name} - Layer {i % tensor.shape[0]}\")\n",
    "        \n",
    "        # Add colorbar if specified\n",
    "        if show_colorbar:\n",
    "            fig.subplots_adjust(right=0.9)\n",
    "            cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "            fig.colorbar(ims[0], cax=cbar_ax)\n",
    "        \n",
    "        # Render figure to numpy array\n",
    "        plt.tight_layout()\n",
    "        fig.canvas.draw()\n",
    "        frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "        frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        frames.append(frame)\n",
    "        \n",
    "        # Close figure to free memory\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Save frames as GIF\n",
    "    imageio.mimsave(output_path, frames, fps=fps, loop=0)\n",
    "    print(f\"GIF saved to: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    tensor1 = np.asarray(tifffile.imread('c12_SR_w1L-561_t1.tif'))\n",
    "    maximum = np.percentile(tensor1[tensor1 > 0], 99.999)\n",
    "    tensor1 = tensor1.clip(min=0.0, max=maximum) / maximum\n",
    "    tensor2 = np.asarray(tifffile.imread('c12_SR_w1L-561_t1.tif'))\n",
    "    maximum = np.percentile(tensor2[tensor2 > 0], 99.999)\n",
    "    tensor2 = tensor2.clip(min=0.0, max=maximum) / maximum\n",
    "    combine_tensors_to_gif(\n",
    "        tensors={\n",
    "            \"Tensor 1\": tensor1,\n",
    "            \"Tensor 2\": tensor2,\n",
    "        },\n",
    "        output_path=\"combined_tensors.gif\",\n",
    "        fps=24,\n",
    "        cmap=\"viridis\"\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_options = random.choice([(0, 1), (1, 2), (0, 2)])\n",
    "axes_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fft\n",
    "\n",
    "\n",
    "# 定义卷积核\n",
    "kernel1 = np.array([[1, 0], [0, 1]])\n",
    "kernel2 = np.array([[0, 1], [1, 0]])\n",
    "\n",
    "# 扩展卷积核到更大的尺寸以便进行傅里叶变换\n",
    "def pad_kernel(kernel, size=64):\n",
    "    padded = np.zeros((size, size))\n",
    "    h, w = kernel.shape\n",
    "    padded[:h, :w] = kernel\n",
    "    return padded\n",
    "\n",
    "# 计算频域响应\n",
    "def compute_frequency_response(kernel):\n",
    "    # padded = pad_kernel(kernel)\n",
    "    freq_response = fft.fft2(kernel)\n",
    "    freq_response = fft.fftshift(freq_response)\n",
    "    magnitude = np.abs(freq_response)\n",
    "    phase = np.angle(freq_response)\n",
    "    return magnitude, phase\n",
    "\n",
    "# 计算两个卷积核的频域响应\n",
    "mag1, phase1 = compute_frequency_response(kernel1)\n",
    "mag2, phase2 = compute_frequency_response(kernel2)\n",
    "\n",
    "# 可视化\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# 显示卷积核\n",
    "im00 = axes[0, 0].imshow(kernel1, cmap='gray')\n",
    "axes[0, 0].set_title('[[1, 0], [0, 1]]')\n",
    "axes[0, 0].axis('off')\n",
    "fig.colorbar(im00, ax=axes[0, 0])  # 添加色条\n",
    "\n",
    "im10 = axes[1, 0].imshow(kernel2, cmap='gray')\n",
    "axes[1, 0].set_title('[[0, 1], [1, 0]]')\n",
    "axes[1, 0].axis('off')\n",
    "fig.colorbar(im10, ax=axes[1, 0])  # 添加色条\n",
    "\n",
    "# 显示幅度响应\n",
    "im01 = axes[0, 1].imshow(np.log(mag1 + 1), cmap='viridis')\n",
    "axes[0, 1].set_title('magnitude (log)')\n",
    "axes[0, 1].axis('off')\n",
    "fig.colorbar(im01, ax=axes[0, 1])  # 添加色条\n",
    "\n",
    "im11 = axes[1, 1].imshow(np.log(mag2 + 1), cmap='viridis')\n",
    "axes[1, 1].set_title('magnitude (log)')\n",
    "axes[1, 1].axis('off')\n",
    "fig.colorbar(im11, ax=axes[1, 1])  # 添加色条\n",
    "\n",
    "# 显示相位响应\n",
    "im02 = axes[0, 2].imshow(phase1, cmap='hsv')\n",
    "axes[0, 2].set_title('phase')\n",
    "axes[0, 2].axis('off')\n",
    "fig.colorbar(im02, ax=axes[0, 2])  # 添加色条\n",
    "\n",
    "im12 = axes[1, 2].imshow(phase2, cmap='hsv')\n",
    "axes[1, 2].set_title('phase')\n",
    "axes[1, 2].axis('off')\n",
    "fig.colorbar(im12, ax=axes[1, 2])  # 添加色条\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.fft as fft\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "# 这里是你提供的函数\n",
    "def fourier_interpolate(tensor, scale_factor=2):\n",
    "    assert tensor.ndim == 5, \"[B, C, D, H, W]\"\n",
    "    \n",
    "    # 3D FFT\n",
    "    tensor_fft = fft.rfftn(tensor, dim=(-3, -2, -1))\n",
    "    batch_size, channels, d, h, w = tensor.shape\n",
    "    \n",
    "    new_d = d * scale_factor\n",
    "    new_h = h * scale_factor\n",
    "    new_w = w * scale_factor\n",
    "    \n",
    "    tensor_fft_padded = torch.zeros(\n",
    "        (batch_size, channels, new_d, new_h, new_w),\n",
    "        dtype=tensor_fft.dtype,\n",
    "        device=tensor_fft.device\n",
    "    )\n",
    "    d_start = (new_d - d) // 2\n",
    "    h_start = (new_h - h) // 2\n",
    "    w_start = (new_w - w) // 2 \n",
    "    \n",
    "    tensor_fft_padded[\n",
    "        :, :, \n",
    "        d_start:d_start+d, \n",
    "        h_start:h_start+h, \n",
    "        w_start:w_start+w] = tensor_fft\n",
    "    \n",
    "    tensor_interpolated = fft.irfftn(tensor_fft_padded, s=(new_d, new_h, new_w), dim=(-3, -2, -1))\n",
    "    \n",
    "    tensor_interpolated = tensor_interpolated * (scale_factor ** 3)\n",
    "    return tensor_interpolated\n",
    "\n",
    "# 创建一个简单的三维测试数据\n",
    "def create_test_volume(size=(8, 8, 8)):\n",
    "    d, h, w = size\n",
    "    volume = torch.zeros(1, 1, d, h, w)\n",
    "    \n",
    "    # 在体数据中创建一些简单的结构\n",
    "    # 中心球体\n",
    "    center = (d//2, h//2, w//2)\n",
    "    radius = min(d, h, w) // 4\n",
    "    \n",
    "    for z in range(d):\n",
    "        for y in range(h):\n",
    "            for x in range(w):\n",
    "                dist = np.sqrt((z-center[0])**2 + (y-center[1])**2 + (x-center[2])**2)\n",
    "                if dist < radius:\n",
    "                    volume[0, 0, z, y, x] = 1.0\n",
    "    \n",
    "    # 添加一些额外的结构\n",
    "    volume[0, 0, d//4, h//4:3*h//4, w//4:3*w//4] = 0.7\n",
    "    volume[0, 0, 3*d//4, h//4:3*h//4, w//4:3*w//4] = 0.7\n",
    "    \n",
    "    return volume\n",
    "\n",
    "# 可视化原始和插值后的体数据\n",
    "def visualize_volume(volume, title=\"Volume Data\"):\n",
    "    # 只可视化一个通道的中心切片\n",
    "    volume = volume[0, 0].cpu().numpy()\n",
    "    d, h, w = volume.shape\n",
    "    \n",
    "    # 创建一个2x2的子图\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # 中间深度切片\n",
    "    ax1 = fig.add_subplot(221)\n",
    "    ax1.imshow(volume[d//2], cmap='viridis')\n",
    "    ax1.set_title(f'Depth slice {d//2}')\n",
    "    \n",
    "    # 中间高度切片\n",
    "    ax2 = fig.add_subplot(222)\n",
    "    ax2.imshow(volume[:, h//2, :], cmap='viridis')\n",
    "    ax2.set_title(f'Height slice {h//2}')\n",
    "    \n",
    "    # 中间宽度切片\n",
    "    ax3 = fig.add_subplot(223)\n",
    "    ax3.imshow(volume[:, :, w//2], cmap='viridis')\n",
    "    ax3.set_title(f'Width slice {w//2}')\n",
    "    \n",
    "    # 3D体渲染（简化版，只显示值大于阈值的点）\n",
    "    ax4 = fig.add_subplot(224, projection='3d')\n",
    "    threshold = 0.1\n",
    "    z, y, x = np.where(volume > threshold)\n",
    "    values = volume[volume > threshold]\n",
    "    scatter = ax4.scatter(x, y, z, c=values, cmap='viridis', alpha=0.6)\n",
    "    ax4.set_title('3D Volume Rendering')\n",
    "    plt.colorbar(scatter, ax=ax4)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 主函数：创建数据、插值并可视化\n",
    "def main():\n",
    "    # 创建原始体数据\n",
    "    original_volume = create_test_volume(size=(16, 16, 16))\n",
    "    print(f\"原始体数据形状: {original_volume.shape}\")\n",
    "    \n",
    "    # 可视化原始数据\n",
    "    visualize_volume(original_volume, \"原始体数据\")\n",
    "    \n",
    "    # 应用傅里叶插值，放大2倍\n",
    "    scale_factor = 2\n",
    "    interpolated_volume = fourier_interpolate(original_volume, scale_factor=scale_factor)\n",
    "    print(f\"插值后体数据形状: {interpolated_volume.shape}\")\n",
    "    \n",
    "    # 可视化插值后的数据\n",
    "    visualize_volume(interpolated_volume, f\"傅里叶插值 (x{scale_factor})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "local_now = datetime.now()\n",
    "print(local_now)  # 输出: 2023-10-09 16:30:00.123456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def log_line_generator(file_path):\n",
    "    \"\"\"生成器：逐行返回日志内容，避免一次性加载\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            yield line\n",
    "\n",
    "def visualize_training(log_file, title=\"Training Process Visualization\", save_path=None, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Visualize multiple metrics during training: batch loss, epoch average loss, validation loss, and learning rate\n",
    "    \n",
    "    Args:\n",
    "        log_data (str): String containing training logs\n",
    "        title (str): Chart title\n",
    "        save_path (str, optional): Path to save the chart. If None, display the chart.\n",
    "        figsize (tuple): Chart size in format (width, height)\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract batch loss data\n",
    "    batch_loss_pattern = r'\\[processing: (\\d+)/\\d+\\] \\[loss: ([\\d.]+)\\]'\n",
    "    batch_matches = re.findall(batch_loss_pattern, log_data)\n",
    "    batch_indices = [int(match[0]) for match in batch_matches]\n",
    "    batch_losses = [float(match[1]) for match in batch_matches]\n",
    "    \n",
    "    # Extract epoch data (assuming validation loss is recorded at the end of each epoch)\n",
    "    epoch_pattern = r'\\[epoch: (\\d+)\\].*?\\[val_loss: ([\\d.]+)\\]'\n",
    "    epoch_matches = re.findall(epoch_pattern, log_data)\n",
    "    epochs = [int(match[0]) for match in epoch_matches]\n",
    "    val_losses = [float(match[1]) for match in epoch_matches]\n",
    "    \n",
    "    # Extract learning rate data\n",
    "    lr_pattern = r'\\[lr: ([\\d.e-]+)\\]'\n",
    "    lr_matches = re.findall(lr_pattern, log_data)\n",
    "    lrs = [float(match) for match in lr_matches]\n",
    "    \n",
    "    # Calculate average training loss per epoch\n",
    "    epoch_avg_losses = []\n",
    "    if epochs and batch_indices:\n",
    "        samples_per_epoch = max(batch_indices)\n",
    "        for epoch in epochs:\n",
    "            start_idx = (epoch - 1) * samples_per_epoch\n",
    "            end_idx = epoch * samples_per_epoch\n",
    "            epoch_losses = batch_losses[start_idx:end_idx]\n",
    "            if epoch_losses:\n",
    "                epoch_avg_losses.append(np.mean(epoch_losses))\n",
    "    \n",
    "    # Create figure and axes\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize, sharex=False)\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    # Plot batch loss and epoch average loss\n",
    "    ax1.plot(batch_indices, batch_losses, 'b-', alpha=0.3, linewidth=1, label='Batch Loss')\n",
    "    if epoch_avg_losses:\n",
    "        ax1.plot(epochs, epoch_avg_losses, 'g-', linewidth=2, marker='o', label='Epoch Average Loss')\n",
    "    if val_losses:\n",
    "        ax1.plot(epochs, val_losses, 'r-', linewidth=2, marker='s', label='Validation Loss')\n",
    "    \n",
    "    ax1.set_title('Training and Validation Loss', fontsize=14)\n",
    "    ax1.set_ylabel('Loss Value', fontsize=12)\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.set_xlim(1, max(batch_indices) if batch_indices else 1)\n",
    "    ax1.set_ylim(0, max(batch_losses + epoch_avg_losses + val_losses) * 1.1 if batch_losses else 1)\n",
    "    \n",
    "    # Plot learning rate changes\n",
    "    ax2.plot(batch_indices, lrs, 'm-', linewidth=2)\n",
    "    ax2.set_title('Learning Rate Schedule', fontsize=14)\n",
    "    ax2.set_xlabel('Training Steps', fontsize=12)\n",
    "    ax2.set_ylabel('Learning Rate', fontsize=12)\n",
    "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax2.set_xlim(1, max(batch_indices) if batch_indices else 1)\n",
    "    ax2.set_yscale('log')  # Use logarithmic scale for better visualization of LR changes\n",
    "    \n",
    "    # Ensure x-axis only shows integers\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to prevent title overlap\n",
    "    \n",
    "    # Save or display the chart\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Chart saved to: {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig, (ax1, ax2)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample log data (including training loss, validation loss, and learning rate)\n",
    "    \n",
    "    # Visualize training process\n",
    "    visualize_training(log_data, title=\"Model Training Process Visualization\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.utils_dataprocessing import fourier_interpolate\n",
    "\n",
    "\n",
    "def create_test_image(size: int = 64) -> torch.Tensor:\n",
    "    \"\"\"Create a test image for demonstration of interpolation effects\"\"\"\n",
    "    # Create grid\n",
    "    x = np.linspace(0, 1, size)\n",
    "    y = np.linspace(0, 1, size)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    \n",
    "    # Create a test image with various frequency components\n",
    "    img = np.sin(2 * np.pi * 5 * xx) + np.cos(2 * np.pi * 3 * yy)\n",
    "    img += 0.5 * np.sin(2 * np.pi * 10 * xx * yy)\n",
    "    img += 0.3 * np.random.randn(size, size)  # Add some noise\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    \n",
    "    return torch.tensor(img, dtype=torch.float32)\n",
    "\n",
    "def visualize_results(original: torch.Tensor, upsampled: torch.Tensor):\n",
    "    \"\"\"Visualize the original and upsampled images\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Display original image\n",
    "    axes[0].imshow(original.numpy(), cmap='gray')\n",
    "    axes[0].set_title(f'Original Image ({original.shape[0]}x{original.shape[1]})')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Display upsampled image\n",
    "    axes[1].imshow(upsampled.numpy(), cmap='gray')\n",
    "    axes[1].set_title(f'After Fourier Interpolation ({upsampled.shape[0]}x{upsampled.shape[1]})')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create test image\n",
    "    test_image = create_test_image(size=64)\n",
    "\n",
    "\n",
    "    kernel = torch.tensor([[[1, 0], [0, 1]], \n",
    "                           [[0, 1], [1, 0]]], requires_grad=False).float() / 2\n",
    "\n",
    "    out_channels, *spatial_dims = kernel.shape\n",
    "    kernel = kernel.view(out_channels, 1, *spatial_dims)\n",
    "    chunks_shape = test_image.shape\n",
    "    batch_chunks = test_image.view(-1, 1, *chunks_shape)\n",
    "    upsampled_image1 = fourier_interpolate(batch_chunks)\n",
    "    conv_layer = torch.nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=2, stride=2, padding=0, bias=False)\n",
    "    conv_layer.weight.data = kernel\n",
    "    batch_chunks = conv_layer(batch_chunks)\n",
    "    visualize_results(test_image, batch_chunks[0][0].detach())\n",
    "    bilinear_image = torch.nn.functional.interpolate(batch_chunks[0][0].detach().view(-1, 1, *batch_chunks[0][0].shape), scale_factor=2, mode='bilinear')\n",
    "    upsampled_image = fourier_interpolate(batch_chunks)\n",
    "    visualize_results(test_image, upsampled_image[0][0].detach())\n",
    "    visualize_results(test_image, upsampled_image[0][1].detach())\n",
    "    visualize_results(test_image, upsampled_image[0][1].detach()/2 + upsampled_image[0][0].detach()/2)\n",
    "    visualize_results(test_image, upsampled_image1[0][0].detach())\n",
    "    visualize_results(test_image, conv_layer(upsampled_image1)[0][0].detach())\n",
    "    visualize_results(test_image, conv_layer(upsampled_image1)[0][1].detach())\n",
    "    visualize_results(test_image, conv_layer(upsampled_image1)[0][1].detach() / 2 + conv_layer(upsampled_image1)[0][0].detach() / 2)\n",
    "    visualize_results(test_image, bilinear_image[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(size=(10, 10, 10, 10, 10))\n",
    "\n",
    "print(X.shape)\n",
    "i_indices, j_indices = torch.triu_indices(10, 10, offset=1)\n",
    "print(i_indices)\n",
    "print(j_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List\n",
    "\n",
    "def calculate_chunk_params(\n",
    "    data_size: int, \n",
    "    chunk_size: int = 256, \n",
    "    overlap_ratio: float = 0.2\n",
    ") -> Tuple[List[Tuple[int, int]], int]:\n",
    "    \"\"\"\n",
    "    计算分块的参数，包括每个块的起始和结束索引\n",
    "    \n",
    "    参数:\n",
    "    - data_size: 原始数据的总大小\n",
    "    - chunk_size: 每个块的目标大小\n",
    "    - overlap_ratio: 重叠区域的比例\n",
    "    \n",
    "    返回:\n",
    "    - 每个块的 (start, end) 索引列表\n",
    "    - 实际的重叠大小\n",
    "    \"\"\"\n",
    "    overlap_size = int(chunk_size * overlap_ratio)\n",
    "    step = chunk_size - overlap_size\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < data_size:\n",
    "        end = min(start + chunk_size, data_size)\n",
    "        chunks.append((start, end))\n",
    "        start += step\n",
    "    \n",
    "    return chunks, overlap_size\n",
    "\n",
    "def generate_block_weights(chunk_size: int, overlap_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    生成块权重函数，确保重叠区域的平滑过渡\n",
    "    \n",
    "    参数:\n",
    "    - chunk_size: 块大小\n",
    "    - overlap_size: 重叠区域大小\n",
    "    \n",
    "    返回:\n",
    "    - 权重数组，形状为 (chunk_size,)\n",
    "    \"\"\"\n",
    "    # 创建全1的中心区域\n",
    "    weights = np.ones(chunk_size)\n",
    "    \n",
    "    # 左侧渐变: 从0到1\n",
    "    if overlap_size > 0:\n",
    "        left_ramp = np.linspace(0, 1, overlap_size)\n",
    "        weights[:overlap_size] = left_ramp\n",
    "    \n",
    "    # 右侧渐变: 从1到0\n",
    "    if overlap_size > 0:\n",
    "        right_ramp = np.linspace(1, 0, overlap_size)\n",
    "        weights[-overlap_size:] = right_ramp\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def apply_chunks_with_blending(\n",
    "    data: np.ndarray, \n",
    "    chunk_size: int = 256, \n",
    "    overlap_ratio: float = 0.2\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    使用分块和渐变处理数据，避免拼接痕迹\n",
    "    \n",
    "    参数:\n",
    "    - data: 原始数据数组\n",
    "    - chunk_size: 每个块的目标大小\n",
    "    - overlap_ratio: 重叠区域的比例\n",
    "    \n",
    "    返回:\n",
    "    - 处理后的完整数据\n",
    "    \"\"\"\n",
    "    data_size = len(data)\n",
    "    chunks, overlap_size = calculate_chunk_params(data_size, chunk_size, overlap_ratio)\n",
    "    weights = generate_block_weights(chunk_size, overlap_size)\n",
    "    \n",
    "    # 初始化结果数组\n",
    "    result = np.zeros_like(data, dtype=float)\n",
    "    blend_weights = np.zeros_like(data, dtype=float)\n",
    "    \n",
    "    for start, end in chunks:\n",
    "        # 提取当前块\n",
    "        chunk = data[start:end].copy().astype(float)\n",
    "        \n",
    "        # 应用权重实现渐变\n",
    "        weighted_chunk = chunk * weights[:end-start]\n",
    "        \n",
    "        # 累积结果和权重\n",
    "        result[start:end] += weighted_chunk\n",
    "        blend_weights[start:end] += weights[:end-start]\n",
    "    \n",
    "    # 归一化处理，避免重叠区域亮度变化\n",
    "    valid_mask = blend_weights > 0\n",
    "    result[valid_mask] /= blend_weights[valid_mask]\n",
    "    \n",
    "    return result.astype(data.dtype)\n",
    "\n",
    "# 示例：可视化分块策略的效果\n",
    "def visualize_chunk_strategy():\n",
    "    # 创建测试数据（带有明显边缘的图像）\n",
    "    data = np.zeros((512, 512), dtype=np.uint8)\n",
    "    data[200:300, 200:300] = 255\n",
    "    \n",
    "    # 应用分块处理\n",
    "    processed_data = apply_chunks_with_blending(\n",
    "        data.flatten(), \n",
    "        chunk_size=128, \n",
    "        overlap_ratio=0.3\n",
    "    ).reshape(data.shape)\n",
    "    \n",
    "    # 生成权重图用于可视化\n",
    "    _, overlap = calculate_chunk_params(data.size, 128, 0.3)\n",
    "    weight_map = generate_block_weights(128, overlap)\n",
    "    \n",
    "    # 可视化结果\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(data, cmap='gray')\n",
    "    axes[0].set_title('原始数据')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].plot(weight_map)\n",
    "    axes[1].set_title('块权重函数')\n",
    "    axes[1].set_xlabel('位置')\n",
    "    axes[1].set_ylabel('权重')\n",
    "    \n",
    "    axes[2].imshow(processed_data, cmap='gray')\n",
    "    axes[2].set_title('处理后的数据')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 运行示例\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_chunk_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16, 16])\n",
      "tensor([[0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216],\n",
      "        [0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216,\n",
      "         0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216, 0.2216]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_z = torch.rand(16)\n",
    "batch_z = batch_z[:, None, None].expand(-1, 16, 16)\n",
    "print(batch_z.shape)\n",
    "print(batch_z[0])\n",
    "block_weight = np.ones([2 * stride_inference - box_size, 2 * stride_inference - box_size], dtype=np.float32)\n",
    "block_weight = np.pad(block_weight, [box_size - stride_inference + 1, box_size - stride_inference + 1], 'linear_ramp')\n",
    "block_weight = torch.from_numpy(block_weight[(slice(1, -1),) * 2])\n",
    "print(block_weight)\n",
    "tifffile.imwrite(f\"{resultFolder}/block_weight.tif\", block_weight.cpu().numpy().astype(np.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SN2N",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
