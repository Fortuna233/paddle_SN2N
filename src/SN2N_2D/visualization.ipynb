{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tyche/paddle_SN2N/data/data_2d/raw_data/1.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from src.utils.utils_dataprocessing import get_all_files, split_and_save_tensor, normalize, resample, fourier_interpolate\n",
    "from src.SN2N_2D.constants_2d import rawdataFolder, datasetsFolder, resultFolder\n",
    "\n",
    "\n",
    "raw_map_list = get_all_files(rawdataFolder)\n",
    "print(raw_map_list[0])\n",
    "raw_map = np.asarray(tifffile.imread(raw_map_list[0]))\n",
    "normalized_map = normalize(raw_map, mode='2d')\n",
    "tifffile.imwrite(f'{resultFolder}/normalized_map.tif', normalized_map) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tyche/paddle_SN2N/data/data_2d/datasets/0_128_128_128.npz\n",
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "datasets = get_all_files(datasetsFolder)\n",
    "print(datasets[0])\n",
    "chunk = np.load(datasets[100])['arr_0']\n",
    "print(chunk.shape)\n",
    "tifffile.imwrite(f'{resultFolder}/chunk.tif', chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tifffile\n",
    "\n",
    "kernel = torch.tensor([[[1, 0], [0, 1]],\n",
    "                      [[0, 1], [1, 0]]]).float() / 2\n",
    "\n",
    "# 使用vstack进行垂直堆叠\n",
    "vertical_kernel = np.vstack((kernel[0], kernel[1]))\n",
    "\n",
    "# 保存为TIF文件\n",
    "tifffile.imwrite(f'{resultFolder}/kernel_vertical.tif', vertical_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 128])\n",
      "torch.Size([2, 64, 64])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 64 and the array at index 1 has size 128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m chunk \u001b[38;5;241m=\u001b[39m conv_layer(chunk\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mchunk\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(chunk\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 14\u001b[0m vertical_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m tifffile\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresultFolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/down_sampled.tif\u001b[39m\u001b[38;5;124m'\u001b[39m, vertical_chunk)\n\u001b[1;32m     16\u001b[0m chunk \u001b[38;5;241m=\u001b[39m fourier_interpolate(chunk\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/SN2N/lib/python3.9/site-packages/numpy/core/shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 64 and the array at index 1 has size 128"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.utils.utils_dataprocessing import fourier_interpolate\n",
    "\n",
    "kernel = torch.tensor([[[1, 0], [0, 1]],\n",
    "                      [[0, 1], [1, 0]]]).float() / 2\n",
    "out_channels, *spatial_dims = kernel.shape\n",
    "kernel = kernel.view(out_channels, 1, *spatial_dims)\n",
    "conv_layer = torch.nn.Conv2d(in_channels=1, out_channels=2, kernel_size=2, stride=2, padding=0, bias=False)\n",
    "conv_layer.weight.data = kernel\n",
    "chunk = torch.from_numpy(np.load(datasets[100])['arr_0'])\n",
    "print(chunk.shape)\n",
    "chunk = conv_layer(chunk.view(1, *chunk.shape))\n",
    "print(chunk.shape)\n",
    "vertical_chunk = np.vstack((chunk[0].detach().numpy(), np.zeros((1, 128), dtype=np.float32), chunk[1].detach().numpy()))\n",
    "tifffile.imwrite(f'{resultFolder}/down_sampled.tif', vertical_chunk)\n",
    "chunk = fourier_interpolate(chunk.view(2, 1, 128, 128)) * 16\n",
    "print(chunk.shape)\n",
    "vertical_chunk1 = np.vstack((chunk[0][0].detach().numpy(), np.zeros((1, 256), dtype=np.float32), chunk[1][0].detach().numpy()))\n",
    "tifffile.imwrite(f'{resultFolder}/up_sampled.tif', vertical_chunk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "load /home/tyche/paddle_SN2N/data/data_2d/params/checkPoint_1\n",
      "num_parameters: 6494716\n"
     ]
    }
   ],
   "source": [
    "from src.utils.utils_train_predict import try_all_gpus\n",
    "from src.SN2N_2D.constants_2d import model, paramsFolder\n",
    "devices = try_all_gpus()\n",
    "model = model.to(devices[0])\n",
    "model = torch.nn.DataParallel(model, device_ids=[0])\n",
    "def init_weights(m):\n",
    "    if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv3d or type(m) == torch.nn.Conv2d:  \n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "current_epoch = len(get_all_files(paramsFolder))\n",
    "print(current_epoch)\n",
    "if current_epoch != 0:\n",
    "    state_dict = torch.load(f'{paramsFolder}/checkPoint_{current_epoch - 1}')\n",
    "    missing_keys, unexpected_keys = model.load_state_dict(state_dict)\n",
    "    if missing_keys:\n",
    "        print(f\"missing_keys: {missing_keys}\")\n",
    "    if unexpected_keys:\n",
    "        print(f\"unused_keys: {unexpected_keys}\")\n",
    "    \n",
    "    print(f'load {paramsFolder}/checkPoint_{current_epoch - 1}')\n",
    "else:\n",
    "    model.apply(init_weights)\n",
    "    print(f'no params found, randomly init model')\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"num_parameters: {total_params}\")\n",
    "chunk = chunk.to(device=devices[0])\n",
    "chunk = model(chunk)\n",
    "vertical_chunk1 = np.vstack((chunk[0][0].cpu().detach().numpy(), np.zeros((1, 256), dtype=np.float32), chunk[1][0].cpu().detach().numpy()))\n",
    "tifffile.imwrite(f'{resultFolder}/predicted.tif', vertical_chunk1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SN2N",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
